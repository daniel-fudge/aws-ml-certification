{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3963e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl \n",
    "import sagemaker\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14638231",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddb81a6",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6b959ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shape</th>\n",
       "      <th>duration</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>weather</th>\n",
       "      <th>physicalEvidence</th>\n",
       "      <th>contact</th>\n",
       "      <th>researchOutcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>circle</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>rain</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>explained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disk</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>partly cloudy</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>explained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>circle</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>clear</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>explained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disk</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>partly cloudy</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>explained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>circle</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>mostly cloudy</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>explained</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    shape  duration  witnesses        weather physicalEvidence contact  \\\n",
       "0  circle         4          1           rain                N       N   \n",
       "1    disk         4          1  partly cloudy                Y       N   \n",
       "2  circle        49          1          clear                N       N   \n",
       "3    disk        13          1  partly cloudy                N       N   \n",
       "4  circle        17          1  mostly cloudy                N       N   \n",
       "\n",
       "  researchOutcome  \n",
       "0       explained  \n",
       "1       explained  \n",
       "2       explained  \n",
       "3       explained  \n",
       "4       explained  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('ufo_fullset.csv', usecols=['shape', 'duration', 'witnesses', 'weather', 'physicalEvidence', 'contact', 'researchOutcome'])\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50da5f9",
   "metadata": {},
   "source": [
    "### Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b6b9081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   explained  duration  witnesses  physicalEvidence  contact  probable  box  \\\n",
      "0          1         4          1                 0        0         0    0   \n",
      "1          1         4          1                 1        0         0    0   \n",
      "2          1        49          1                 0        0         0    0   \n",
      "3          1        13          1                 0        0         0    0   \n",
      "4          1        17          1                 0        0         0    0   \n",
      "\n",
      "   circle  disk  light  ...  pyramid  sphere  square  triangle  fog  \\\n",
      "0       1     0      0  ...        0       0       0         0    0   \n",
      "1       0     1      0  ...        0       0       0         0    0   \n",
      "2       1     0      0  ...        0       0       0         0    0   \n",
      "3       0     1      0  ...        0       0       0         0    0   \n",
      "4       1     0      0  ...        0       0       0         0    0   \n",
      "\n",
      "   mostly_cloudy  partly_cloudy  rain  snow  stormy  \n",
      "0              0              0     1     0       0  \n",
      "1              0              1     0     0       0  \n",
      "2              0              0     0     0       0  \n",
      "3              0              1     0     0       0  \n",
      "4              1              0     0     0       0  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18000 entries, 0 to 17999\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype\n",
      "---  ------            --------------  -----\n",
      " 0   explained         18000 non-null  uint8\n",
      " 1   duration          18000 non-null  int64\n",
      " 2   witnesses         18000 non-null  int64\n",
      " 3   physicalEvidence  18000 non-null  int64\n",
      " 4   contact           18000 non-null  int64\n",
      " 5   probable          18000 non-null  uint8\n",
      " 6   box               18000 non-null  uint8\n",
      " 7   circle            18000 non-null  uint8\n",
      " 8   disk              18000 non-null  uint8\n",
      " 9   light             18000 non-null  uint8\n",
      " 10  oval              18000 non-null  uint8\n",
      " 11  pyramid           18000 non-null  uint8\n",
      " 12  sphere            18000 non-null  uint8\n",
      " 13  square            18000 non-null  uint8\n",
      " 14  triangle          18000 non-null  uint8\n",
      " 15  fog               18000 non-null  uint8\n",
      " 16  mostly_cloudy     18000 non-null  uint8\n",
      " 17  partly_cloudy     18000 non-null  uint8\n",
      " 18  rain              18000 non-null  uint8\n",
      " 19  snow              18000 non-null  uint8\n",
      " 20  stormy            18000 non-null  uint8\n",
      "dtypes: int64(4), uint8(17)\n",
      "memory usage: 861.5 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data_clean = data.fillna('unknown')\n",
    "data_clean.replace(' ', '_', regex=True, inplace=True)\n",
    "data_clean.replace(('Y', 'N'), (1, 0), inplace=True)\n",
    "\n",
    "data_clean = pd.get_dummies(data_clean, columns=['researchOutcome', 'shape', 'weather'])\n",
    "data_clean.drop(columns=['researchOutcome_unexplained', 'shape_unknown', 'weather_clear'], inplace=True)\n",
    "data_clean.columns = data_clean.columns.str.replace(\"researchOutcome_\", \"\")\n",
    "data_clean.columns = data_clean.columns.str.replace(\"shape_\", \"\")\n",
    "data_clean.columns = data_clean.columns.str.replace(\"weather_\", \"\")\n",
    "headers = ['explained'] + [c for c in data_clean.columns if c != 'explained']\n",
    "data_clean = data_clean[headers]\n",
    "print(data_clean.head())\n",
    "print(data_clean.info())\n",
    "data_np = data_clean.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2928764",
   "metadata": {},
   "source": [
    "### Save the data to train, validate and test csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c4867c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12600, 21)\n",
      "(3600, 21)\n",
      "(1800, 21)\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(data_np.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "train_end = int(data_np.shape[0]*0.7)\n",
    "validate_end = int(data_np.shape[0]*0.9)\n",
    "train = data_np[indices[:train_end]]\n",
    "validate = data_np[indices[train_end:validate_end]]\n",
    "test = data_np[indices[validate_end:]]\n",
    "print(train.shape)\n",
    "print(validate.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "03d7bc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'acg-ml-certification-df'\n",
    "\n",
    "train_name = 'train.csv'\n",
    "validate_name = 'validate.csv'\n",
    "test_name = 'test.csv'\n",
    "test_true_name = 'test-true.csv'\n",
    "\n",
    "np.savetxt(train_name, train.astype(int), fmt='%i', delimiter=',')\n",
    "np.savetxt(validate_name, validate.astype(int), fmt='%i', delimiter=',')\n",
    "np.savetxt(test_name, test[:, 1:].astype(int), fmt='%i', delimiter=',')\n",
    "np.savetxt(test_true_name, test[:, 0].astype(int), fmt='%i', delimiter=',')\n",
    "\n",
    "for name in [train_name, validate_name, test_name, test_true_name]:\n",
    "    s3_client.upload_file(name, bucket_name, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ff2832",
   "metadata": {},
   "source": [
    "## Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bde1d455",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-29 03:06:36 Starting - Starting the training job...\n",
      "2021-05-29 03:07:02 Starting - Launching requested ML instancesProfilerReport-1622257596: InProgress\n",
      "......\n",
      "2021-05-29 03:08:03 Starting - Preparing the instances for training......\n",
      "2021-05-29 03:09:03 Downloading - Downloading input data...\n",
      "2021-05-29 03:09:33 Training - Training image download completed. Training in progress..\u001b[34m[2021-05-29 03:09:35.323 ip-10-0-183-194.ec2.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-05-29:03:09:35:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2021-05-29:03:09:35:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2021-05-29:03:09:35:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2021-05-29:03:09:35:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2021-05-29:03:09:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2021-05-29:03:09:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2021-05-29:03:09:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2021-05-29:03:09:35:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2021-05-29:03:09:35:INFO] Single node training.\u001b[0m\n",
      "\u001b[34m[2021-05-29:03:09:35:INFO] Train matrix has 12600 rows and 20 columns\u001b[0m\n",
      "\u001b[34m[2021-05-29:03:09:35:INFO] Validation matrix has 3600 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.02897#011validation-error:0.03167\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.02889#011validation-error:0.03028\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.02897#011validation-error:0.03028\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.02905#011validation-error:0.03000\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.02897#011validation-error:0.03000\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.02921#011validation-error:0.03000\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.02921#011validation-error:0.03000\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.02921#011validation-error:0.03000\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.02921#011validation-error:0.03000\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.02905#011validation-error:0.03000\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.02905#011validation-error:0.03000\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.02913#011validation-error:0.03000\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.02913#011validation-error:0.03000\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.02913#011validation-error:0.03000\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.02913#011validation-error:0.03000\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.02913#011validation-error:0.03000\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.02905#011validation-error:0.03000\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.02897#011validation-error:0.02972\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.02897#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.02897#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.02897#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.02897#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.02889#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.02889#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.02889#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.02881#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.02881#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.02889#011validation-error:0.02972\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.02889#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.02881#011validation-error:0.02972\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.02873#011validation-error:0.02972\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.02881#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.02881#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.02881#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.02881#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.02873#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.02873#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.02881#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.02873#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.02865#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.02865#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.02865#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.02865#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.02865#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.02865#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.02881#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.02865#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.02849#011validation-error:0.02944\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.02857#011validation-error:0.02917\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.02833#011validation-error:0.02917\u001b[0m\n",
      "\n",
      "2021-05-29 03:10:03 Uploading - Uploading generated training model\n",
      "2021-05-29 03:10:03 Completed - Training job completed\n",
      "Training seconds: 53\n",
      "Billable seconds: 53\n"
     ]
    }
   ],
   "source": [
    "output_bucket = sagemaker.Session().default_bucket()\n",
    "output_path = f\"s3://{output_bucket}\"\n",
    "job_name = f'xgboost-{datetime.now().strftime(\"%Y%m%d%H%M%S\")}'\n",
    "\n",
    "hyperparameters = {\n",
    "    'num_round': 50,\n",
    "    'eta': 0.2,\n",
    "    'objective':\"binary:logistic\"}\n",
    "\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", boto3.Session().region_name, \"1.2-2\")\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(image_uri=xgboost_container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.m5.2xlarge', \n",
    "                                          volume_size=5, \n",
    "                                          output_path=output_path)\n",
    "\n",
    "# define the data type and paths to the training and validation datasets\n",
    "train_input = sagemaker.inputs.TrainingInput(f\"s3://{bucket_name}/train.csv\", content_type=\"csv\")\n",
    "validation_input = sagemaker.inputs.TrainingInput(f\"s3://{bucket_name}/validate.csv\", content_type=\"csv\")\n",
    "\n",
    "# execute the XGBoost training job\n",
    "estimator.fit(inputs={'train': train_input, 'validation': validation_input}, job_name=job_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50545d51",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "18e610f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_key = job_name + '/output/model.tar.gz'\n",
    "boto3.resource('s3').Bucket(output_bucket).download_file(model_key, 'model.tar.gz')\n",
    "os.system('gtar -xvf model.tar.gz')\n",
    "with open(\"xgboost-model\", \"rb\") as f:\n",
    "    booster = pkl.load(f)\n",
    "pred = (booster.predict(xgb.DMatrix(test[:, 1:].astype(int))) + 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0ca01245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9744\n",
      "Recall:    0.9837\n",
      "Precision: 0.9806\n",
      "f1:        0.9822\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy:  {accuracy_score(test[:, 0], pred):.4f}\")\n",
    "print(f\"Recall:    {recall_score(test[:, 0], pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(test[:, 0], pred):.4f}\")\n",
    "print(f\"f1:        {f1_score(test[:, 0], pred):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
